{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2.5.1 Exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. When we measure data using sensory devices across multiple users we often see substantial differences between the sensory values we obtain. Identify at least three potential causes for these differences."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<ol>\n",
    "  <li>Different ways of wearing sensors. For instance, an individual can have the sensory device on the dominant arm, and another on the non-dominant arm.</li>\n",
    "  <li>Battery saving modes. For instance, to extend battery life, one can set many smartwatches to measure heart rate at lower frequencies, resulting in less data in the same timespan.</li>\n",
    "  <li>Continuing on the topic of heart rate, differences in activity or fitness between users can result in high variation of data obtained.</li>\n",
    "</ol>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. We have seen that we can make trade-offs in terms of the granularity at which we consider the measurements in our basic dataset. We have shown the difference between a granularity of $\\Delta$ t = 0.25 s and $\\Delta$ t = 60 s. We arrived at a choice for $\\Delta$ t = 0.25 s for our case, but let us think a bit more general: think of four criteria that play a role in deciding on the granularity for the measurements of a dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<ol>\n",
    "  <li>The time-scales at which the events take place. Measuring heart rate should necessarily be done at lower timeframes when compared to measuring if an individual is seated or active.</li>\n",
    "  <li>The resources required for running the model. If the granularity is lowered to encompass more measurements per time span, this will mean the model has to be both trained and run on more data. This requires more processing power, especially for larger datasets.</li>\n",
    "  <li>The smoothing of the data. As more data points are added per timeframe, smoothing between points is reduced which implies a greater amount of outlying datapoints in the dataset.</li>\n",
    "  <li>Reducing missing values. If the granulatiry is higher than the events that we wish to measure, we will sometimes not be able to capture the events successfully.</li>\n",
    "</ol>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. We have identified two tasks we are going to tackle for the crowdsignals data. Think of at least two other machine learning tasks that could be performed on the crowdsignals dataset and argue why they could be relevant to support a user (when doing so, keep in mind the different learning approaches discussed in Sect. 1.3.2)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The two tasks mentioned in the book:\n",
    "\n",
    "(1) a classification problem, namely predicting the label (i.e. activity) based on the sensors, and \n",
    "\n",
    "(2) a regression problem, namely predicting the heart rate based on the other sensory values and the activity.\n",
    "\n",
    "Two new tasks:\n",
    "<ol>\n",
    "  <li>A regression problem: Measuring distance traveled based on the accelerometer (is already done via gps usually of course, but not actively mentioned here). Would allow the user to track distance while running or walking without the use of a GPS.</li>\n",
    "  <li>A classification task: predicting whether the phone will be used based on sensors. This allows the phone to turn on the screen without direct input from the users.</li>\n",
    "</ol>"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('mlqs': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "df14c868dcf36846bb0b1108068b57bf98ecdd06336877ba57dbad26c2cedfa4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}